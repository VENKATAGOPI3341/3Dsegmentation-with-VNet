{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports and Setup\n"
      ],
      "metadata": {
        "id": "cJ3caN1tOOmV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports.py\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "from monai.config import print_config\n",
        "from monai.data import CacheDataset\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd, Orientationd, ScaleIntensityRanged,\n",
        "    CropForegroundd, RandCropByPosNegLabeld, RandFlipd, RandRotate90d, RandZoomd, EnsureTyped\n",
        ")\n",
        "from monai.networks.nets import VNet\n",
        "from monai.losses import DiceLoss\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "# Ensure reproducibility\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "# Set up device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "WxaxrmuVOUaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Data Preparation\n"
      ],
      "metadata": {
        "id": "09qWwd3ZOYkD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data_preparation.py\n",
        "from imports import *\n",
        "\n",
        "def prepare_data(data_dir):\n",
        "    image_files = glob.glob(os.path.join(data_dir, \"images/*.nii\"))\n",
        "    label_files = glob.glob(os.path.join(data_dir, \"labels/*.nii\"))\n",
        "\n",
        "    # Ensure the list is sorted if needed\n",
        "    image_files.sort()\n",
        "    label_files.sort()\n",
        "\n",
        "    # Create a list of dictionaries for dataset\n",
        "    data_list = [{\"image\": img, \"label\": lbl} for img, lbl in zip(image_files, label_files)]\n",
        "\n",
        "    # Split dataset into training and validation sets\n",
        "    split_index = int(len(data_list) * 0.8)\n",
        "    train_files = data_list[:split_index]\n",
        "    val_files = data_list[split_index:]\n",
        "\n",
        "    return train_files, val_files\n",
        "\n",
        "def get_transforms():\n",
        "    train_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"image\", \"label\"]),\n",
        "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"image\"], a_min=-100, a_max=400, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "            RandCropByPosNegLabeld(\n",
        "                keys=[\"image\", \"label\"],\n",
        "                label_key=\"label\",\n",
        "                spatial_size=(128, 128, 64),\n",
        "                pos=1,\n",
        "                neg=1,\n",
        "                num_samples=4,\n",
        "                image_key=\"image\",\n",
        "                image_threshold=0,\n",
        "            ),\n",
        "            RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[0], prob=0.10),\n",
        "            RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[1], prob=0.10),\n",
        "            RandFlipd(keys=[\"image\", \"label\"], spatial_axis=[2], prob=0.10),\n",
        "            RandRotate90d(keys=[\"image\", \"label\"], prob=0.10, max_k=3),\n",
        "            RandZoomd(keys=[\"image\", \"label\"], min_zoom=0.9, max_zoom=1.1, prob=0.10),\n",
        "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    val_transforms = Compose(\n",
        "        [\n",
        "            LoadImaged(keys=[\"image\", \"label\"]),\n",
        "            EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "            Spacingd(keys=[\"image\", \"label\"], pixdim=(1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "            Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "            ScaleIntensityRanged(keys=[\"image\"], a_min=-100, a_max=400, b_min=0.0, b_max=1.0, clip=True),\n",
        "            CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "            EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return train_transforms, val_transforms\n",
        "\n",
        "def load_data(train_files, val_files, train_transforms, val_transforms):\n",
        "    train_ds = CacheDataset(data=train_files, transform=train_transforms, cache_rate=0.1)\n",
        "    val_ds = CacheDataset(data=val_files, transform=val_transforms, cache_rate=0.1)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
        "    val_loader = DataLoader(val_ds, batch_size=1, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, val_loader\n"
      ],
      "metadata": {
        "id": "r9F3A6pcOcc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Setup\n"
      ],
      "metadata": {
        "id": "qOod2mbkOep9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model_setup.py\n",
        "from imports import *\n",
        "\n",
        "def initialize_model():\n",
        "    model = VNet(spatial_dims=3, in_channels=1, out_channels=5).to(device)  # 4 organs + 1 background\n",
        "    return model\n",
        "\n",
        "def get_loss_function_and_optimizer(model):\n",
        "    loss_function = DiceLoss(include_background=False, to_onehot_y=True, softmax=True)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "    return loss_function, optimizer\n"
      ],
      "metadata": {
        "id": "FZEZmtcQOhew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Validation\n"
      ],
      "metadata": {
        "id": "fYZi53BnOkkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training_validation.py\n",
        "from imports import *\n",
        "from data_preparation import prepare_data, get_transforms, load_data\n",
        "from model_setup import initialize_model, get_loss_function_and_optimizer\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, loss_function, optimizer, model_dir, num_epochs=100, val_interval=2):\n",
        "    # Initialize Dice metrics for each organ\n",
        "    dice_metric_liver = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "    dice_metric_right_kidney = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "    dice_metric_left_kidney = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "    dice_metric_spleen = DiceMetric(include_background=False, reduction=\"mean\")\n",
        "\n",
        "    # Define variables to track best performance\n",
        "    best_metric_liver = -1\n",
        "    best_metric_right_kidney = -1\n",
        "    best_metric_left_kidney = -1\n",
        "    best_metric_spleen = -1\n",
        "\n",
        "    # Lists to store metrics over epochs\n",
        "    liver_metrics = []\n",
        "    right_kidney_metrics = []\n",
        "    left_kidney_metrics = []\n",
        "    spleen_metrics = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        epoch_loss = 0\n",
        "        step = 0\n",
        "        for batch_data in train_loader:\n",
        "            step += 1\n",
        "            inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "        # Print training results\n",
        "        epoch_loss /= step\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        if (epoch + 1) % val_interval == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                val_steps = 0\n",
        "                dice_liver = 0\n",
        "                dice_right_kidney = 0\n",
        "                dice_left_kidney = 0\n",
        "                dice_spleen = 0\n",
        "                for batch_data in val_loader:\n",
        "                    val_steps += 1\n",
        "                    inputs, labels = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
        "                    outputs = sliding_window_inference(inputs, (128, 128, 64), 4, model)\n",
        "\n",
        "                    # Compute metrics for each organ\n",
        "                    outputs = torch.softmax(outputs, dim=1)\n",
        "                    dice_metric_liver(y_pred=outputs[:, 1], y=labels[:, 1])\n",
        "                    dice_metric_right_kidney(y_pred=outputs[:, 2], y=labels[:, 2])\n",
        "                    dice_metric_left_kidney(y_pred=outputs[:, 3], y=labels[:, 3])\n",
        "                    dice_metric_spleen(y_pred=outputs[:, 4], y=labels[:, 4])\n",
        "\n",
        "                # Calculate average Dice score for each organ\n",
        "                dice_liver = dice_metric_liver.aggregate().item()\n",
        "                dice_right_kidney = dice_metric_right_kidney.aggregate().item()\n",
        "                dice_left_kidney = dice_metric_left_kidney.aggregate().item()\n",
        "                dice_spleen = dice_metric_spleen.aggregate().item()\n",
        "\n",
        "                dice_metric_liver.reset()\n",
        "                dice_metric_right_kidney.reset()\n",
        "                dice_metric_left_kidney.reset()\n",
        "                dice_metric_spleen.reset()\n",
        "\n",
        "                print(f\"Validation Dice Liver: {dice_liver:.4f}\")\n",
        "                print(f\"Validation Dice Right Kidney: {dice_right_kidney:.4f}\")\n",
        "                print(f\"Validation Dice Left Kidney: {dice_left_kidney:.4f}\")\n",
        "                print(f\"Validation Dice Spleen: {dice_spleen:.4f}\")\n",
        "\n",
        "                # Save best model checkpoints\n",
        "                if dice_liver > best_metric_liver:\n",
        "                    best_metric_liver = dice_liver\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_liver_model.pth\"))\n",
        "\n",
        "                if dice_right_kidney > best_metric_right_kidney:\n",
        "                    best_metric_right_kidney = dice_right_kidney\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_right_kidney_model.pth\"))\n",
        "\n",
        "                if dice_left_kidney > best_metric_left_kidney:\n",
        "                    best_metric_left_kidney = dice_left_kidney\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_left_kidney_model.pth\"))\n",
        "\n",
        "                if dice_spleen > best_metric_spleen:\n",
        "                    best_metric_spleen = dice_spleen\n",
        "                    torch.save(model.state_dict(), os.path.join(model_dir, \"best_metric_spleen_model.pth\"))\n",
        "\n",
        "                # Append metrics\n",
        "                liver_metrics.append(dice_liver)\n",
        "                right_kidney_metrics.append(dice_right_kidney)\n",
        "                left_kidney_metrics.append(dice_left_kidney)\n",
        "                spleen_metrics.append(dice_spleen)\n",
        "\n",
        "    print(\"Training complete.\")\n",
        "\n",
        "    # Plotting Dice scores over epochs for each organ\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.plot(range(1, len(liver_metrics) + 1), liver_metrics, label='Liver')\n",
        "    plt.plot(range(1, len(right_kidney_metrics) + 1), right_kidney_metrics, label='Right Kidney')\n",
        "    plt.plot(range(1, len(left_kidney_metrics) + 1), left_kidney_metrics, label='Left Kidney')\n",
        "    plt.plot(range(1, len(spleen_metrics) + 1), spleen_metrics, label='Spleen')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Dice Score')\n",
        "    plt.title('Dice Score over Epochs for each Organ')\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "BZ0CC8UbOn-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JrOHP3INPB1R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}